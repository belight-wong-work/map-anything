{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9214748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1：MapAnything（Colab）在线模型推理 + 本机图片上传 + 下载结果\n",
    "#\n",
    "# 目标：完全在 Google Colab 云端运行推理：\n",
    "# - 模型：从 HuggingFace 在线加载（不使用你本地的离线模型文件）\n",
    "# - 图片：从你本机上传到 Colab（或你也可以改为 Drive 路径）\n",
    "# - 结果：在 Colab 生成后打包下载到你本机（你再保存到任意本地路径）\n",
    "#\n",
    "# 说明：\n",
    "# - 本 Notebook 调用 scripts/demo_images_only_inference.py 进行推理\n",
    "# - 在线加载模型需要 Colab 能访问网络（HuggingFace）\n",
    "# - 8GB 显存建议：--memory_efficient_inference + --max_views/--stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a289b83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2：Colab 环境准备（可直接运行）\n",
    "!nvidia-smi || true\n",
    "\n",
    "# 方式 A（推荐）：用你自己的 fork/仓库（确保包含你本地改动，比如 demo_images_only_inference.py 支持 --checkpoint_path）\n",
    "# 将下面地址替换成你的 fork，或把仓库上传到 Drive 再 %cd 到对应目录。\n",
    "REPO_URL = \"https://github.com/facebookresearch/map-anything.git\"  # TODO: 换成你的 fork（如果你改过脚本）\n",
    "\n",
    "%cd /content\n",
    "!rm -rf map-anything\n",
    "!git clone $REPO_URL\n",
    "%cd /content/map-anything\n",
    "\n",
    "# 安装（推理最小依赖）\n",
    "!pip -q install -U pip\n",
    "!pip -q install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bbc212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3：挂载 Google Drive（可选，但离线模型/图片一般都放 Drive）\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "# TODO：按你的实际路径修改：\n",
    "IMAGE_FOLDER = \"/content/drive/MyDrive/your_images_folder\"\n",
    "CKPT_PATH = \"/content/drive/MyDrive/checkpoints/model.safetensors\"\n",
    "CONFIG_JSON_PATH = \"/content/drive/MyDrive/checkpoints/config.json\"\n",
    "\n",
    "# 输出必须是一个文件名（建议 .glb）\n",
    "OUTPUT_GLB = \"/content/drive/MyDrive/mapanything_outputs/output.glb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6007258c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%writefile` not found.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4：在 Colab 里生成一个“等价于 demo_images_only_inference.py”的脚本（在线模型）\n",
    "#\n",
    "# 说明：VS Code 本地 Notebook 的 Python kernel 可能没有 IPython 的 `%%writefile` magic。\n",
    "# 这里改为用纯 Python 写文件，兼容 Colab/VS Code/普通 Python。\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "out_file = Path(\"demo_images_only_inference_colab.py\")\n",
    "script = '''import argparse\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from mapanything.models import MapAnything\n",
    "from mapanything.utils.image import load_images\n",
    "from mapanything.utils.viz import predictions_to_glb\n",
    "\n",
    "\n",
    "def build_parser() -> argparse.ArgumentParser:\n",
    "    p = argparse.ArgumentParser(description=\"MapAnything images-only inference (Colab inline script)\")\n",
    "    p.add_argument(\"--image_folder\", type=str, required=True)\n",
    "    p.add_argument(\"--model\", type=str, default=None, help=\"HF repo id or local dir. Default: facebook/map-anything\")\n",
    "    p.add_argument(\"--apache\", action=\"store_true\", help=\"Use facebook/map-anything-apache\")\n",
    "    p.add_argument(\"--memory_efficient_inference\", action=\"store_true\", default=False)\n",
    "    p.add_argument(\"--stride\", type=int, default=1, help=\"Load every nth image\")\n",
    "    p.add_argument(\"--max_views\", type=int, default=None, help=\"Limit number of views\")\n",
    "    p.add_argument(\"--no_amp\", action=\"store_true\", default=False)\n",
    "    p.add_argument(\"--amp_dtype\", type=str, default=\"bf16\", choices=[\"bf16\", \"fp16\", \"fp32\"])\n",
    "    p.add_argument(\"--save_glb\", action=\"store_true\", default=False)\n",
    "    p.add_argument(\"--output_path\", type=str, default=\"output.glb\")\n",
    "    return p\n",
    "\n",
    "\n",
    "def main() -> None:\n",
    "    args = build_parser().parse_args()\n",
    "\n",
    "    os.environ.setdefault(\"PYTORCH_CUDA_ALLOC_CONF\", \"expandable_segments:True\")\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(\"Using device:\", device)\n",
    "\n",
    "    if args.model is None:\n",
    "        model_id = \"facebook/map-anything-apache\" if args.apache else \"facebook/map-anything\"\n",
    "    else:\n",
    "        model_id = args.model\n",
    "    print(\"Loading model:\", model_id)\n",
    "    model = MapAnything.from_pretrained(model_id).to(device)\n",
    "\n",
    "    stride = max(int(args.stride), 1)\n",
    "    print(\"Loading images from:\", args.image_folder, \"(stride=\", stride, \")\")\n",
    "    views = load_images(args.image_folder, stride=stride)\n",
    "    if args.max_views is not None:\n",
    "        views = views[: max(int(args.max_views), 1)]\n",
    "    print(\"Loaded\", len(views), \"views\")\n",
    "\n",
    "    print(\"Running inference...\")\n",
    "    outputs = model.infer(\n",
    "        views,\n",
    "        memory_efficient_inference=bool(args.memory_efficient_inference),\n",
    "        use_amp=not args.no_amp,\n",
    "        amp_dtype=args.amp_dtype,\n",
    "        apply_mask=True,\n",
    "        mask_edges=True,\n",
    "    )\n",
    "    print(\"Inference complete!\")\n",
    "\n",
    "    if not args.save_glb:\n",
    "        print(\"Skipping GLB export (--save_glb not specified)\")\n",
    "        return\n",
    "\n",
    "    out_path = Path(args.output_path)\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    world_points_list = []\n",
    "    images_list = []\n",
    "    masks_list = []\n",
    "    for pred in outputs:\n",
    "        pts3d_np = pred[\"pts3d\"][0].detach().cpu().numpy()\n",
    "        image_np = pred[\"img_no_norm\"][0].detach().cpu().numpy()\n",
    "        mask = pred[\"mask\"][0].squeeze(-1).detach().cpu().numpy().astype(bool)\n",
    "        world_points_list.append(pts3d_np)\n",
    "        images_list.append(image_np)\n",
    "        masks_list.append(mask)\n",
    "\n",
    "    predictions = {\n",
    "        \"world_points\": np.stack(world_points_list, axis=0),\n",
    "        \"images\": np.stack(images_list, axis=0),\n",
    "        \"final_masks\": np.stack(masks_list, axis=0),\n",
    "    }\n",
    "\n",
    "    print(\"Exporting GLB to:\", str(out_path))\n",
    "    scene_3d = predictions_to_glb(predictions, as_mesh=True)\n",
    "    scene_3d.export(str(out_path))\n",
    "    print(\"Done:\", str(out_path))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "\n",
    "out_file.write_text(script, encoding=\"utf-8\")\n",
    "print(\"Wrote:\", str(out_file.resolve()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7cebdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5：调用上一个 Cell 生成的脚本运行推理，然后下载结果到本机\n",
    "import os\n",
    "from pathlib import Path\n",
    "from google.colab import files\n",
    "\n",
    "# 在线加载模型：facebook/map-anything（默认 CC-BY-NC）；如果你需要 Apache 许可可换成 facebook/map-anything-apache\n",
    "MODEL_ID = \"facebook/map-anything\"\n",
    "\n",
    "# 输出到 Colab 本地文件系统，随后下载到你本机\n",
    "OUT_DIR = Path(\"/content/mapanything_outputs\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_GLB = str(OUT_DIR / \"output.glb\")\n",
    "\n",
    "# 8GB 显存建议参数（你可以逐步调大 max_views 或减小 stride）\n",
    "MAX_VIEWS = 30\n",
    "STRIDE = 2\n",
    "AMP_DTYPE = \"fp16\"\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "!python demo_images_only_inference_colab.py \\\n",
    "  --image_folder \"$IMAGE_FOLDER\" \\\n",
    "  --model \"$MODEL_ID\" \\\n",
    "  --memory_efficient_inference \\\n",
    "  --amp_dtype \"$AMP_DTYPE\" \\\n",
    "  --stride $STRIDE \\\n",
    "  --max_views $MAX_VIEWS \\\n",
    "  --save_glb \\\n",
    "  --output_path \"$OUTPUT_GLB\"\n",
    "\n",
    "# 下载到本机（浏览器会提示保存；你可选择任意本地路径）\n",
    "files.download(OUTPUT_GLB)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
